file_name: ./saved_model/volume_finetune_cascaded
t1_data:
  path_to_tsv_train: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/label_and_file_path/20211206/t1_train.tsv'
  path_to_tsv_val: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/label_and_file_path/20211206/t1_val.tsv'
  path_to_tsv_test: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/label_and_file_path/20211206/t1_test.tsv'
  batch_size: 4
  val_batch_size: 2
  workers: 4
  percentage_usage: 1.0
flair_data:
  path_to_tsv_train: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/label_and_file_path/20211206/flair_train.tsv'
  path_to_tsv_val: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/label_and_file_path/20211206/flair_val.tsv'
  path_to_tsv_test: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/label_and_file_path/20211206/flair_test.tsv'
  batch_size: 4
  val_batch_size: 2
  workers: 4
  percentage_usage: 1.0
exp_name: volume_finetune_cascaded
visdom:
  port: 8064 
  # server: skygpu07 
  server: None
model:
  arch: ours
  input_channel: 1
  nhid: 512
  feature_dim: 1024
  n_label: 3
  expansion: 8
  num_blocks: 0
  type_name: conv3x3x3
  norm_type: Instance
adv_model:
  nhid: 36
  out_dim: 12
mmse_model:
  nhid: 64
training_parameters:
  use_age: False
  flair_pretrain: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/saved_model/volume_retrain_flair_2/volume_retrain_flair_train_perc_100.0_expansion_8_model_low_loss.pth.tar'
  t1_pretrain: '/gpfs/home/lc3424/capstone/2021_dementia/lc3424_workspace/experiments/20211102/saved_model/volume_finetune_2/volume_finetune_new_train_perc_100.0_expansion_8_model_low_loss.pth.tar'
  pretrain: 
  max_iter: 16000
  start_epoch: 0
  epochs: 150
  print_freq: 10
  max_grad_l2_norm:
  report_interval: 100
  snapshot_interval: 1000

optimizer:
  method: SGD
  par:
    lr: 0.01
    weight_decay: 0.000

